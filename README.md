# A Flexible Recipe for Deployment to Multiple Environments Using Pulumi, Kubernetes and Github Actions
The following is a recipe for managing and testing application deployments in different environments (local, staging, feature branch). 
Inspired by [Basecamp's approach](https://m.signalvnoise.com/seamless-branch-deploys-with-kubernetes/).

## Key Features
- Local deployment recipe
- AWS deployment recipe

## Prerequisites
- [AWS account](https://aws.amazon.com/account/)
- [Cloudflare account](https://www.cloudflare.com/en-ca/)
- [Github account](https://github.com)
- [Pulumi account](https://www.pulumi.com/)
- [Pulumi installation](https://www.pulumi.com/docs/get-started/kubernetes/begin/)

## Tools
- [Certmanager](https://github.com/cert-manager/cert-manager) and [Let's Encrypt](https://letsencrypt.org/) to manage SSL certifications
- [Cloudflare](https://www.cloudflare.com/en-ca/) for domain management
- [Earthly](https://earthly.dev/) for reproducible builds
- [Elixir](https://elixir-lang.org/) and [Phoenix](https://www.phoenixframework.org/) for the demo application
- [Github Actions](https://github.com/features/actions) to trigger deployments on different branches
- [Github Container Registry](https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry) to save Docker images
- [Minikube](https://minikube.sigs.k8s.io/docs/start/) to Kubernetes clusters locally 
- [Nginx](https://www.nginx.com/) as the reverse proxy
- [Pulumi](https://www.pulumi.com/) for instrastructure as code
- [Postgres](https://www.postgresql.org/) as the database inside the Kubernetes cluster

## Comments/Questions
Please open an issue or a discussion or send me a message on [Twitter](https://twitter.com/vinnerroy).

## Usage
Start by running `pulumi new kubernetes-typescript` inside your project which will generate scaffold in the folder of your choice and then use `Earthfile` in the root directory and inside `apps` and files inside the `deployment` folder to augment your app. The contents inside `deployment` were first generated by running `pulumi new kubernetes-typescript` inside an empty `deployment` folder.

## Local Deployment
You might want to call your [Pulumi stack](https://www.pulumi.com/docs/intro/concepts/stack/) something like `local` for this use-case.

By default, kubectl gets configured to access the kubernetes cluster control plane inside minikube when the `minikube start` command is run.
To resync the kubeconfig setup to connect to minikube, use `minikube update-context`.

To make Docker images accessible to Minikube, run `eval $(minikube docker-env)` before building your image with Earthly.

A `isMinikube` config variable is used to differenriate between local and remote deployments
`pulumi config set isMinikube false`


### Ingress
If you plan to use an Ingress resource and want to test in Ingress, you'll want to follow the Minikube steps [here](https://minikube.sigs.k8s.io/docs/handbook/addons/ingress-dns/).
The steps are:
1. `minikube start`
2. `minikube addons enable ingress`
3. `minikube addons enable ingress-dns`
4. `minikube ip` -> copy this IP
5. `sudo mkdir /etc/resolver` on Mac
5. `sudo vim /etc/resolver/minikube-test` or `sudo nano /etc/resolver/minikube-test` or other
6. Write the following inside the `minikube-test` file:
```
domain test
nameserver PUT-MINIKUBE-IP-HERE
search_order 1
timeout 5
```

### Note on Load Balancer
The Pulumi docs state that Minikube does not support the `LoadBalancer` service type, but this is no longer true as per [Minikube's docs](https://minikube.sigs.k8s.io/docs/handbook/accessing/#loadbalancer-access)
However, you must run: `minikube tunnel` before `pulumi up` for the load balancer service-type to work. Without minikube tunnel, kubernetes will be showing external IP as “pending”.
If you run into a problem with the Minikube tunnel, you can use `minikube tunnel --cleanup` to clean up orphaned processes before starting a tnnel.
Use `kubectl get svc` to get the IP to access the service.

If you run into an issue similar to: 
```
Post "https://ingress-nginx-controller-admission.ingress-nginx.svc:443/networking/v1/ingresses?timeout=10s": x509: certificate signed by unknown authority
```
then you can run `kubectl get -A ValidatingWebhookConfiguration` to find the webhook validation to delete followed by:
`kubectl delete -A ValidatingWebhookConfiguration ingress-nginx-admission`. Running `pulumi up` after deleting this resource should work correctly.

### Clean up
Use `pulumi destroy` to destroy the cluster and optionally use `pulumi stack rm` to delete the stack history from Pulumi's servers.

## Production Deployment
You might want to call your [Pulumi stack](https://www.pulumi.com/docs/intro/concepts/stack/) something like `production` for this use-case.

Work in progress...

## Beta Deployment
You might want to call your [Pulumi stack](https://www.pulumi.com/docs/intro/concepts/stack/) something like `beta` for this use-case.

Work in progress...

## Feature Branch/PR Deployment
You probably want to name your [Pulumi stack](https://www.pulumi.com/docs/intro/concepts/stack/) automatically based on the branch name for this use-case.

Work in progress...


## Bitnami Postgres Debugging
When using the Bitnami Helm Postgres chart, you'll have to delete the associated `pvc` when changing the Postgres password otherwise the password in the `postgresql` secret will be out of sync with the real password.
https://stackoverflow.com/questions/63917524/helm-postgres-password-authentication-failed